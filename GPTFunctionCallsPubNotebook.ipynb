{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a28f8a03",
   "metadata": {},
   "source": [
    "# An exmple of using GPT Functions calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711b26be",
   "metadata": {},
   "source": [
    "\"Function calling\" is a quite reliable approach to extracting structured, deterministic information from large language models like GPT-4. We can now describe functions to GPT-4-0613 and GPT-3.5-turbo-0613 models and have the model automatically choose to create a JSON object output with parameters to call those functions. It's a novel approach to establishing dependable connections between GPT and third-party applications and APIs. OpenAI fine-tuned these models to recognize when a function should be invoked (based on user input) and return JSON that follows the function signature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab417ab",
   "metadata": {},
   "source": [
    "**In this example, we will use free to use weather API from openweathermap.org to get the current weather information for a place requested by the user.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3919d62a",
   "metadata": {},
   "source": [
    "Install PYOWM, a Python wrapper around OpenWeatherMap web APIs to get weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f742e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyowm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aebc1d8",
   "metadata": {},
   "source": [
    "Import the usual suspects. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "274dca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "#import to use OpenWeatherMap API for Weather Function example\n",
    "import pyowm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9348bb3d",
   "metadata": {},
   "source": [
    "Import the API Keys. \n",
    "<div class=\"alert alert-block alert-info\">Note: OpenWeatherMap has free API keys with limited functionalities. Use the free one.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bdc2857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API Keys from files\n",
    "openai.api_key = open(\"openai_api.key\", \"r\").read().strip(\"\\n\")\n",
    "owm_api_key=open(\"owm_api.key\", \"r\").read().strip(\"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bac05e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">This is a placeholder cell to test out various functions of the OWM API. Feel free to explore it. :)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test API call before punching it into GPT ... delete cell later after creating real function below. \n",
    "from pyowm.owm import OWM\n",
    "#from pyowm.utils import timestamps\n",
    "owm = OWM(owm_api_key)\n",
    "\n",
    "mgr = owm.weather_manager()\n",
    "observation = mgr.weather_at_place('Arizona,US')\n",
    "location_temperature = observation.weather.temperature('fahrenheit')['temp']\n",
    "weathernow = observation.weather.detailed_status \n",
    "print(location_temperature)\n",
    "print (weathernow)\n",
    "\n",
    "#daily_forecaster = mgr.forecast_at_place('Arizona,US', 'daily')    # looks like free API has its limitations. :)\n",
    "#tomorrow = timestamps.tomorrow()                                   # datetime object for tomorrow\n",
    "#weather = daily_forecaster.get_weather_at(tomorrow)                # the weather forecast\n",
    "#print(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c107d5",
   "metadata": {},
   "source": [
    "#### User Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd1fec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "userInput = \"What's the weather like in Jamaica?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45aa0f3",
   "metadata": {},
   "source": [
    "Before Function calls were a possibility, we will do the following to get a completion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b80bbfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI, I don't have real-time data. However, Jamaica typically has a tropical climate with hot and humid weather, with little variation throughout the year. Temperatures average between 80-90°F (27-32°C) during the day and around 70°F (21°C) at night. It can rain frequently, but the island also enjoys plenty of sunshine. The rainier months are usually May and October to November. Always check a reliable weather forecast before planning your visit.\n"
     ]
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": userInput}],\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de19313",
   "metadata": {},
   "source": [
    "**Function calling lets us overcome GPT's inherent limitations, in this case real time information, by allowing us to invoke function(s) to provide the information that the user requested by supplementing GPT's inherent capabilities.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a670d6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Here's what we will do.\n",
    "    \n",
    "1. Define the function to get current weather of a place requested by the user. In our example here, it's Arizona. \n",
    "2. Send the conversation and all available functions to GPT (yes, you can send more than one functions to the LLM).\n",
    "3. Function can be set as auto for LLM to decide if the context requires it to make the call. In this example, we will be explicit and ask LLM to make the call.\n",
    "4. Check if GPT wanted to call a function.\n",
    "5. Send the info on the function call and function response to GPT get the final completion from GPT with the function call results.\n",
    "6. Print the final completion.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210aa88a",
   "metadata": {},
   "source": [
    "Define the function that gets the current weather of a location from https://openweathermap.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10daafb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location, unit):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    from pyowm.owm import OWM\n",
    "    owm = OWM(owm_api_key)\n",
    "    mgr = owm.weather_manager()\n",
    "    observation = mgr.weather_at_place(location)\n",
    "    location_temperature = observation.weather.temperature(unit)['temp']\n",
    "    weathernow = observation.weather.detailed_status \n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": location_temperature,\n",
    "        \"unit\": unit,\n",
    "        \"currentweather\": weathernow,\n",
    "        \"forecast\": [\"sunny\", \"windy\"], #fake, hard-coded values to show that we can do the obvious. :)\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed4e707",
   "metadata": {},
   "source": [
    "Now, let's get a GPT completion with the function call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fedea99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "Based on the location information GPT decided the temperature units should be  celsius\n",
      "****************************************\n",
      "Response from the model: The current temperature in Jamaica is 24.61 degrees Celsius with moderate rain. The forecast predicts sunny and windy weather.\n",
      "****************************************\n",
      "Completion Object: {\n",
      "  \"id\": \"chatcmpl-86VByKSTzygDWOcMgMW4EofUVqSeI\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1696560562,\n",
      "  \"model\": \"gpt-4-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"The current temperature in Jamaica is 24.61 degrees Celsius with moderate rain. The forecast predicts sunny and windy weather.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 93,\n",
      "    \"completion_tokens\": 24,\n",
      "    \"total_tokens\": 117\n",
      "  }\n",
      "}\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "# courtesy OpenAI -- minor changes to code, the model, and required parameters \n",
    "\n",
    "def run_conversation():\n",
    "    # Step 1: send the conversation and available functions to GPT\n",
    "    messages = [{\"role\": \"user\", \"content\": userInput }]\n",
    "    functions = [\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\", \"unit\"],\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-0613\",  \n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "    # Step 2: check if GPT wanted to call a function\n",
    "    if response_message.get(\"function_call\"):\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        print('Based on the location information GPT decided the temperature units should be ', function_args.get(\"unit\"))\n",
    "        print ('****************************************')\n",
    "        function_response = function_to_call(\n",
    "            location=function_args.get(\"location\"),\n",
    "            unit=function_args.get(\"unit\"),\n",
    "        )\n",
    "\n",
    "\n",
    "        # Step 4: send the info on the function call and function response to GPT\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4-0613\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "        print('Response from the model:' , second_response.choices[0].message.content)\n",
    "        print ('****************************************')\n",
    "        return second_response\n",
    "print ('****************************************')    \n",
    "print('Completion Object:', run_conversation())\n",
    "print ('****************************************')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyenv)",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
